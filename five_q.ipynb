{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from digtextsimilaritysearch.indexer.faiss_indexer \\\n",
    "    import FaissIndexer\n",
    "from digtextsimilaritysearch.vectorizer.sentence_vectorizer \\\n",
    "    import SentenceVectorizer\n",
    "from digtextsimilaritysearch.storage.hbase_adapter \\\n",
    "    import HBaseAdapter\n",
    "from digtextsimilaritysearch.process_documents.document_processor \\\n",
    "    import DocumentProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "idx_name = 'FlatL2_Aug_test.index'\n",
    "idx_path = os.path.join(cwd, 'saved_indexes', idx_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: https://tfhub.dev/google/universal-sentence-encoder/2\nINFO:tensorflow:Using /var/folders/cc/5jv4m9b567z2fzyhvc104dz80000gn/T/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading model\nInitializing TF Session...\n"
     ]
    }
   ],
   "source": [
    "# Note: ensure hbase docker is running\n",
    "# docker pull dajobe/hbase\n",
    "# docker run -d -p 9090:9090 -p 2181:2181 -v <path>:/data dajobe/hbase\n",
    "# <path>: /Users/ljferrer/PycharmProjects/dig-text-similarity-search/HBaseStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: https://tfhub.dev/google/universal-sentence-encoder/2\nINFO:tensorflow:Using /var/folders/cc/5jv4m9b567z2fzyhvc104dz80000gn/T/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading model\nInitializing TF Session...\n"
     ]
    }
   ],
   "source": [
    "fi = FaissIndexer(path_to_index_file=idx_path)\n",
    "sv = SentenceVectorizer()\n",
    "hb = HBaseAdapter('localhost')\n",
    "\n",
    "dp = DocumentProcessor(indexer=fi, vectorizer=sv, hbase_adapter=hb,\n",
    "                       index_save_path=idx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = 'Before 8 September 2018, will the UK request an extension ' \\\n",
    "     'to Article 50 for leaving the EU?'\n",
    "\n",
    "q1 = 'Will China execute or be targeted in an acknowledged ' \\\n",
    "     'national military attack before 1 September 2018?'\n",
    "\n",
    "q2 = 'Will the WHO declare a Public Health Emergency of ' \\\n",
    "     'International Concern (PHEIC) before 1 September 2018?'\n",
    "\n",
    "q3 = 'Will UK Prime Minister Theresa May announce her resignation, ' \\\n",
    "     'lose a confidence vote, or otherwise vacate her office ' \\\n",
    "     'before 8 September 2018?'\n",
    "\n",
    "q4 = 'Will American pastor Andrew Brunson leave Turkey ' \\\n",
    "     'before 8 September 2018?'\n",
    "\n",
    "queries = [q0, q1, q2, q3, q4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: TTransportException(type=4, message='TSocket read 0 bytes'), while retrieving record: 1052463, from table: dig\nException: TTransportException(type=4, message='TSocket read 0 bytes'), while retrieving record: 972619, from table: dig\nException: TTransportException(type=4, message='TSocket read 0 bytes'), while retrieving record: 1088713, from table: dig\n"
     ]
    }
   ],
   "source": [
    "doc_hits = dp.query_text(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
